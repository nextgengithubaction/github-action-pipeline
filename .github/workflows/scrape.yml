name: Selenium Scraper
on:
  workflow_call:
  workflow_dispatch:
  push:
    paths: '**/scrape.yml'

# Variables taken from repo secrets - can be replaced with passed variables for composite actions
env:
  WEBSITE: ${{ vars.SELENIUM_WEBSITE }}
  LOAD_TIME: ${{ vars.SELENIUM_LOAD_TIME }}
  PAGE_SOURCE: ${{ vars.SELENIUM_PAGE_SOURCE }}
  ELEMENT: ${{ vars.SELENIUM_ELEMENT }}
  
jobs:
  scrape:
    runs-on: dindrunner
    name: Selenium Scraper
        
    steps:
      - name: Repo checkout
        uses: actions/checkout@v4
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: 3.9
      - name: Installed package list
        run: apt list --installed
      # - name: Remove Chrome
      #   run: sudo apt purge google-chrome-stable
      # - name: Remove default Chromium
      #   run: sudo apt purge chromium-browser
      - name: Update package repositories
        run: sudo apt update
      - name: Install a new Chromium
        run: sudo apt install -y chromium-browser
      - name: Install all necessary packages
        run: pip install requests beautifulsoup4 pandas webdriver-manager selenium
      - name: Run the scraping script
        run: python ./.github/scripts/scraper.py $WEBSITE $LOAD_TIME $PAGE_SOURCE $ELEMENT
      - name: Selenium scrape completed
        run: echo "Selenium scrape completed"
