name: Selenium Scraper
on:
  workflow_call:
  workflow_dispatch:
  push:
    paths: '**/scrape.yml'

env:
  WEBSITE: ${{ secrets.SELENIUM_WEBSITE }}
  LOAD_TIME: ${{ secrets.SELENIUM_LOAD_TIME }}
  PAGE_SOURCE: ${{ secrets.SELENIUM_PAGE_SOURCE }}
  ELEMENT: ${{ secrets.SELENIUM_ELEMENT }}

jobs:
  scrape:
    runs-on: ubuntu-latest
    name: Selenium Scraper
        
    steps:
      - name: Repo checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: 3.9

      - name: Install necessary packages
        run: |
          sudo apt update
          sudo apt install -y chromium-browser
          pip install requests beautifulsoup4 pandas webdriver-manager selenium

      - name: Run the scraping script
        run: |
          python ./.github/scripts/scraper.py "$WEBSITE" "$LOAD_TIME" "$PAGE_SOURCE" "$ELEMENT"
        continue-on-error: true

      - name: Check Selenium scrape status
        if: ${{ failure() }}
        run: echo "Selenium scrape failed"

      - name: Check Selenium scrape status
        if: ${{ success() }}
        run: echo "Selenium scrape completed"
